{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from simpleautodiff import Dual,Variable,sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Input: -1.0\n",
      "Function Value: -4.459767882269113\n",
      "Function Symbolic Derivative: 3.504367159953579\n",
      "< Dual value: -4.459767882269113, derivative: 3.504367159953579 >\n",
      "--------------------------------\n",
      "Function Input: 0.5\n",
      "Function Value: -1.4026444100543694\n",
      "Function Symbolic Derivative: 1.1084382073126584\n",
      "< Dual value: -1.4026444100543694, derivative: 1.1084382073126582 >\n",
      "--------------------------------\n",
      "Function Input: 3.0\n",
      "Function Value: 0.004762468816939924\n",
      "Function Symbolic Derivative: -0.8682732520785479\n",
      "< Dual value: 0.004762468816939924, derivative: -0.8682732520785477 >\n",
      "--------------------------------\n",
      "Function Input: 2.0\n",
      "Function Value: 0.47882974016169233\n",
      "Function Symbolic Derivative: 0.5480851436957535\n",
      "< Dual value: 0.47882974016169233, derivative: 0.5480851436957535 >\n",
      "--------------------------------\n",
      "TESTING Variable\n",
      "Function Input: -1.0\n",
      "Function Value: -4.459767882269113\n",
      "Function Symbolic Derivative: 3.504367159953579\n",
      "Variable Function Output Value: < Variable value: -4.459767882269113, gradient: 0.0 >\n",
      "Input value: < Variable value: -1.0, gradient: 3.504367159953579 >\n",
      "--------------------------------\n",
      "Function Input: 0.5\n",
      "Function Value: -1.4026444100543694\n",
      "Function Symbolic Derivative: 1.1084382073126584\n",
      "Variable Function Output Value: < Variable value: -1.4026444100543694, gradient: 0.0 >\n",
      "Input value: < Variable value: 0.5, gradient: 1.1084382073126582 >\n",
      "--------------------------------\n",
      "Function Input: 3.0\n",
      "Function Value: 0.004762468816939924\n",
      "Function Symbolic Derivative: -0.8682732520785479\n",
      "Variable Function Output Value: < Variable value: 0.004762468816939924, gradient: 0.0 >\n",
      "Input value: < Variable value: 3.0, gradient: -0.8682732520785479 >\n",
      "--------------------------------\n",
      "Function Input: 2.0\n",
      "Function Value: 0.47882974016169233\n",
      "Function Symbolic Derivative: 0.5480851436957535\n",
      "Variable Function Output Value: < Variable value: 0.47882974016169233, gradient: 0.0 >\n",
      "Input value: < Variable value: 2.0, gradient: 0.5480851436957535 >\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# some examples\n",
    "\n",
    "def super_complicated_function(x):\n",
    "    return x * sin(x+6.)**2. / 2. - 2. / 2.**x\n",
    "\n",
    "# by running the above in mathematica (wolfram alpha)\n",
    "# direct link: https://www.wolframalpha.com/input/?i=derivative+x+*+sin%28x%2B6.%29**2.+%2F+2.+-+2%2F2**x\n",
    "def d_super_complicated_function(x):\n",
    "    return 2**(1 - x) * math.log(2) + 0.5 * sin(x + 6)**2 + x * math.sin(x + 6) * math.cos(x + 6)\n",
    "\n",
    "for x in [-1., 0.5, 3., 2.]:\n",
    "    print('Function Input: {}'.format(x))\n",
    "    print('Function Value: {}'.format(super_complicated_function(x)))\n",
    "    print('Function Symbolic Derivative: {}'.format(d_super_complicated_function(x)))\n",
    "    print(super_complicated_function(Dual(x, 1.)))\n",
    "    print('-'*32)\n",
    "\n",
    "\n",
    "print('TESTING Variable')\n",
    "\n",
    "for x in [-1., 0.5, 3., 2.]:\n",
    "    print('Function Input: {}'.format(x))\n",
    "    print('Function Value: {}'.format(super_complicated_function(x)))\n",
    "    print('Function Symbolic Derivative: {}'.format(d_super_complicated_function(x)))\n",
    "    x_v = Variable(x)\n",
    "    L = super_complicated_function(x_v)\n",
    "    print('Variable Function Output Value: {}'.format(L))\n",
    "    L.backward()\n",
    "    print('Input value: {}'.format(x_v))\n",
    "    print('-'*32)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Variable value: 9.276772529143361, gradient: 0.0 >\n",
      "< Variable value: 2.0, gradient: 1.1823960755919083 >\n"
     ]
    }
   ],
   "source": [
    "def forward_fn(x):\n",
    "    for n in range(5):\n",
    "        if n % 2 == 0:\n",
    "            x = 3.*x\n",
    "        else:\n",
    "            x = x**(1./n) + 1./n\n",
    "        \n",
    "    return x\n",
    "\n",
    "x = Variable(2.)\n",
    "y = forward_fn(x)\n",
    "print(y)\n",
    "\n",
    "y.backward()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Initial Value ----\n",
      "fn(x): < Variable value: 63.2, gradient: 0.0 >\n",
      "Target: 42.0\n",
      "intial guess for x: < Variable value: 3.0, gradient: 0.0 >\n",
      "---- Converged Value ----\n",
      "fn(x): < Variable value: 42.00014691908245, gradient: 0.0 >\n",
      "Target: 42.0\n",
      "converged x: < Variable value: 2.601581019114941, gradient: 0.0 >\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Wolfram alpha minimum: \\n# min{(x^2 + 0.2 (x - 2)^5 + 2 x^3 - 42)^2} = 0 at x≈2.60158\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn(x):\n",
    "    return x**2 + 0.2*(x-2)**5 + 2*x**3\n",
    "\n",
    "# initialization\n",
    "x = Variable(3.)\n",
    "target = 42.\n",
    "print('---- Initial Value ----')\n",
    "print('fn(x): {}'.format(fn(x)))\n",
    "print('Target: {}'.format(target))\n",
    "print('intial guess for x: {}'.format(x))\n",
    "\n",
    "\n",
    "for n in range(20):\n",
    "    L = (fn(x) - target)**2\n",
    "    L.backward()\n",
    "    # gradient descent update\n",
    "    x.value = x.value - 1e-4 * x.gradient\n",
    "    # clear the gradients\n",
    "    x.clear_gradient()\n",
    "    \n",
    "print('---- Converged Value ----')    \n",
    "print('fn(x): {}'.format(fn(x)))\n",
    "print('Target: {}'.format(target))\n",
    "print('converged x: {}'.format(x))\n",
    "\n",
    "\n",
    "'''\n",
    "# Wolfram alpha minimum: \n",
    "# min{(x^2 + 0.2 (x - 2)^5 + 2 x^3 - 42)^2} = 0 at x≈2.60158\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
